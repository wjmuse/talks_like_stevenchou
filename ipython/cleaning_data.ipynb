{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.0.2\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.11 (default, Dec  6 2015 18:57:58)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os,sys,datetime,re,chardet,time,urllib2\n",
    "import matplotlib.pyplot as plt\n",
    "from jianfan import jtof\n",
    "from os import walk\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "spark_home = os.environ.get('SPARK_HOME', None)\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME environment variable is not set')\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python'))\n",
    "sys.path.insert(0, os.path.join(spark_home, 'python/lib/py4j-0.10.3-src.zip'))\n",
    "execfile(os.path.join(spark_home, 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/97家有喜事\n",
      "utf-8\n",
      "../data/功夫\n",
      "utf-8\n",
      "../data/唐伯虎秋香v2\n",
      "utf-8\n",
      "../data/唐伯虎點秋香v1\n",
      "utf-8\n",
      "../data/國產凌凌漆\n",
      "utf-8\n",
      "../data/少林足球\n",
      "utf-8\n",
      "../data/武狀元蘇乞兒\n",
      "ascii\n",
      "../data/逃學威龍\n",
      "utf-8\n",
      "../data/食神\n",
      "utf-8\n",
      "../data/鹿鼎記神龍教\n",
      "utf-8\n"
     ]
    }
   ],
   "source": [
    "ori_files = []\n",
    "\n",
    "for (dirpath, dirnames, filenames) in walk('../data/'):\n",
    "    for filename in filenames:\n",
    "        print dirpath + filename\n",
    "        with open(dirpath + filename,'r') as f:\n",
    "            _data = f.readlines()\n",
    "            if len(_data) > 2:\n",
    "                print chardet.detect(_data[2])['encoding']\n",
    "                ori_files.append((_data,chardet.detect(_data[2])['encoding']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ori_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "還有誰？\n",
      "這麽漂亮的一個女人\n",
      "就因為往地上吐了一口口水\n",
      "就被你們給抓到這兒來\n",
      "還有王法嗎？\n",
      "還有法律嗎？\n",
      "你們局長都得給我們鱷魚幫面子\n",
      "要不然他就當不了這個局長\n",
      "你他媽的不認識我？\n",
      "對不起，我真的不知道她是你的太太\n",
      "你還敢躲！\n",
      "走！\n",
      "看什麽看？ 沒見過這麽帥的老大？\n",
      "我做什麽生意都不會做電影\n",
      "星期天電影院一個人都沒有\n",
      "車子呢？\n",
      "回去！\n",
      "叫人！\n",
      "不用發了，下巴老\n",
      "你打警察的時候\n",
      "你的小弟已經全都被我搞定了\n",
      "斧頭幫，我跟你拼了\n",
      "慢著！慢著！\n",
      "你還記得嗎？我還請你吃過飯呢\n",
      "琛哥\n",
      "大哥，你放過我吧\n",
      "別傻了，大嫂\n",
      "我不殺女人，你走吧\n",
      "謝謝大哥\n",
      "警察出來洗地了\n",
      "1，2，3\n",
      "苦力強，行不行啊？\n",
      "行！\n",
      "阿鬼，算帳\n",
      "å”‰\n",
      "多少錢？\n",
      "送的，送的！\n",
      "你可真懂事啊\n",
      "謝了\n",
      "小意思，小意思\n",
      "我回去了，跟老婆商量一下\n",
      "減你的租金\n",
      "Thank you!\n",
      "包租公，早\n",
      "包租公！早\n",
      "小朱，又長高了\n",
      "來過來，叔叔給你檢查身體\n",
      "包租公，這麽巧啊\n",
      "巧什麽巧啊\n",
      "別這樣…！\n",
      "勝哥，這件衣服的叉我想開高點了\n",
      "沒問題！\n",
      "哎呀，有流星啊！\n",
      "阿珍！你來真的？\n",
      "哎呀包租公，你怎麽這樣啊？\n",
      "阿珍…你別走啊，阿珍\n",
      "再聊一會兒，來，別走啊你\n",
      "阿珍\n",
      "包租婆\n",
      "包租婆！\n",
      "為什麽突然之間沒水了呢？\n",
      "水費不用花錢哪？你們這些混蛋\n",
      "這個月房租也不交\n",
      "還那麽多廢話說\n",
      "但是我的頭洗到一半，你把水閘關了\n",
      "我不光是現在關\n",
      "從明天開始，逢一、三、五停水\n",
      "二、四、六間歇性供水，怎樣？\n",
      "斜眉歪眼，一個個鬼哭狼嚎什麽？\n",
      "找死啊？\n",
      "我看你們都活賦了！\n",
      "Good morning , 包租婆！\n",
      "果你媽個頭啊！\n",
      "你今天要是再不交租的話\n",
      "我就燒了你鋪子\n",
      "笑，笑什麽啊？\n",
      "笑就不用交租了，老屁眼\n",
      "這麽有力氣，活該你一輩子做苦力\n",
      "欠我幾個月租金\n",
      "早上連招呼也不打一聲\n",
      "累死你個王八蛋！\n",
      "別以為你長得帥就不打你\n",
      "餵，怎麽買粥買那麽久啊？\n",
      "粥不是買回來了嗎\n",
      "我剛才幫忙扶個老婆婆過馬路嘛\n",
      "那你在這幹嘛？\n",
      "我看看有沒有色鬼偷看人洗澡\n",
      "六嬸，有沒有色鬼偷看你洗澡？\n",
      "六嬸，無憑無據，你別亂指啊你\n",
      "神經病，無憑無據\n",
      "別鬧了！\n",
      "叔叔，可不可以教我們踢球啊？\n",
      "還踢球！\n",
      "哪位剪頭？\n",
      "我大哥\n",
      "請坐\n",
      "剪完！謝謝五毛錢\n",
      "å“‡\n",
      "很漂亮吧？\n",
      "幹嘛剪那麽漂亮？\n",
      "誰叫你剪的漂亮的？\n",
      "找茬啊？\n",
      "大哥，你別生氣\n",
      "他是我朋友，讓我來跟他說\n",
      "斧頭幫大哥，兩把斧頭你也親眼看到了\n",
      "壞人哪\n",
      "你把他頭剪那麽漂亮要死人的，知道嗎？\n",
      "不知道\n",
      "哎呀，所以說，你真是的！\n",
      "那跟你聊得很投緣，你賠點醫藥費\n",
      "我幫你擺平，好不好？\n",
      "不好！\n",
      "大哥，不要拿斧頭啊你，收起來先\n",
      "我再跟他說\n",
      "這次幫你出頭，你親眼看見的\n",
      "我沒騙你啊\n",
      "你方不方便，多少拿點出來\n",
      "擺個十桌八桌，要不半桌也行\n",
      "哦，原來你勒索我\n",
      "大哥\n",
      "大哥！\n",
      "大哥\n",
      "你死定了，我大哥一睡醒就砍人\n",
      "哇，你看他就要醒了，馬上\n",
      "我不怕\n",
      "就算殺了一個我，還有千千萬萬個我\n",
      "出頭鳥啊？斧頭幫大哥在里面睡午覺\n",
      "哪個不怕死的，向前一步啊\n",
      "哦，那就是沒的商量\n",
      "好啊，江湖規矩，單挑啊\n",
      "就是一個對一個，誰也不想犯規啊\n",
      "拿蔥的那個大嬸，出來！\n",
      "表情那麽兇幹什麽啊？\n",
      "以為打得贏我啊你？\n",
      "我讓你一拳都可以，打我啊\n",
      "大嬸，幹什麽的你？\n",
      "俺是耕田的\n",
      "耕田就好好耕田吧你，滾回田里去吧\n",
      "有毛病！\n",
      "做錯事還頂嘴啊你！\n",
      "不是看你有毛病，我早K你了\n",
      "那個矮子！五尺差半寸那個，就是你\n",
      "矮要承認，挨打站穩，出來啊\n",
      "這輩子我最看不起那些不老實的人了\n",
      "坐下！\n",
      "戴眼鏡那老伯那麽拽，出來\n",
      "我不是叫你啊老伯，我叫那個…\n",
      "那個小鬼！\n",
      "小鬼，我忍你很久了，出來\n",
      "行了…夠大了夠大了\n",
      "哎，沒有一個像人的\n",
      "是你們自己不爭氣的噢\n",
      "今天的決鬥取消了\n",
      "他勒索我\n",
      "哦，肥婆，負責人就是你，是吧？\n",
      "肥婆了！\n",
      "唉，斧頭幫啊！\n",
      "斧頭幫了！\n",
      "大哥！\n",
      "大哥了！\n",
      "賠湯藥費啊你！\n",
      "湯藥費了！\n",
      "自己人！\n",
      "自己人了你！\n",
      "好了\n",
      "我靠，靠\n",
      "有種啊你！我叫人！\n",
      "腰里揣著死耗子，冒充打獵的\n",
      "我看你叫誰！\n",
      "一枝穿雲箭，千軍萬馬來相見\n",
      "等死吧你，你別走啊！你啊\n",
      "買棺材吧你\n",
      "誰扔的炮仗？\n",
      "自己人，大哥\n",
      "你們這麽多事幹什麽啊？\n",
      "下雨了，趕快回家收衣服\n",
      "肥婆！\n",
      "你也想勒索我？\n",
      "我不怕\n",
      "啊？\n",
      "我…\n",
      "怎麽會這樣？有沒有看見？\n",
      "別動！斷了！\n",
      "叫人…叫人！\n",
      "走！\n",
      "大哥，你別生氣\n",
      "你吃了東西沒有？我這里…\n",
      "老實點！\n",
      "不要！\n",
      "是誰幹的？\n",
      "我數三下\n",
      "１…\n",
      "２…\n",
      "是我做的\n",
      "琛哥，這些貨行不行？\n",
      "對不起，琛哥\n",
      "小孩子別看，轉過去\n",
      "扔出去\n",
      "從來只有我們斧頭幫欺負人\n",
      "沒有人敢欺負我們\n",
      "今天我們傷了二十幾個弟兄\n",
      "就因為這兩家夥，冒充我們斧頭幫\n",
      "琛哥…這個還用您操心嗎？\n",
      "您現在迷迷糊糊的，小心別摔著了\n",
      "那個誰，搞定他\n",
      "神偷啊，會開鎖\n",
      "混口飯吃，給個機會\n",
      "好，有兩下子，把那個也開了吧\n",
      "ä¾†\n",
      "我只數三聲啊\n",
      "快點\n",
      "預備，３！\n",
      "真的有兩下子！\n",
      "琛哥\n",
      "其實我們是很想加入斧頭幫\n",
      "所以才去冒充的\n",
      "給個機會吧你，好不好？\n",
      "你殺過人沒有？\n",
      "殺人這種事，我整天都有這種想法的\n",
      "先殺個人讓我看看\n",
      "那我現在就去殺人了，好不好？\n",
      "å—¯\n",
      "去吧！\n",
      "多謝琛哥！\n",
      "這種他媽的擔色，總有一天用得著的\n",
      "我說過多少遍了跟你\n",
      "要狠嘛\n",
      "狠一點！\n",
      "再狠一點，樣子！\n",
      "要演就演全套吧你\n",
      "不要每次都睡著了\n",
      "裝狠很累的\n",
      "累？糊口啊，大哥\n",
      "這個世界，滿街是錢，遍地是女人\n",
      "誰能夠下決心就可以爭的贏\n",
      "誰能夠把握機會就能出人頭地\n",
      "現在機會來了\n",
      "狠下心殺個人，正式加入斧頭幫\n",
      "那麽錢和女人就全都有了\n",
      "千萬別像這些臭要飯的，你看你看\n",
      "沒一個上進，混吃等死\n",
      "看什麽啊，四眼崽？\n",
      "再看打爆你的眼鏡\n",
      "去死吧！要飯的\n",
      "有種下車啊你！\n",
      "你真要去殺人啊？\n",
      "那還用說！\n",
      "我先殺光四眼崽\n",
      "再殺城寨里那個肥婆還有那些王八蛋街坊\n",
      "那些王八蛋街坊武功很高的\n",
      "武功，我也會啊！\n",
      "你也會？\n",
      "難道我學過如來神掌也要說給你聽嗎？\n",
      "唉，小弟，小弟，別走啊\n",
      "哇，不得了，不得了啊\n",
      "你有道靈光從天靈蓋噴出來，你知道嗎？\n",
      "年紀輕輕的就有一身橫練的筋骨\n",
      "簡直百年一見的練武奇材啊\n",
      "如果有一天，讓你打通任督二脈\n",
      "那還不飛龍上天哪\n",
      "正所謂：我不入地獄，誰入地獄\n",
      "警惡懲奸，維護世界和平這個任務\n",
      "就交給你了，好嗎？\n",
      "å””\n",
      "這本《如來神掌秘笈》是無價之寶\n",
      "我看與你有緣，收你十塊錢，傳授給你吧\n",
      "你把全部家當都給他了？\n",
      "是，本來打算用這筆錢去讀書\n",
      "將來可以做個醫生或者律師\n",
      "但是為了維護世界和平\n",
      "放開那女孩！\n",
      "哇，如來神掌啊\n",
      "還賣兩分錢一本\n",
      "真有錢啊\n",
      "想打死人啊？\n",
      "一個傻子，一個啞巴，死一邊去吧\n",
      "從此以後，我明白好人沒好報\n",
      "我要做壞人\n",
      "我要殺人\n",
      "冰淇淋啊！\n",
      "哪里？\n",
      "兩杯，我要奶油的\n",
      "我要巧克力！\n",
      "看什麽？沒看過吃東西不給錢啊？\n",
      "追哦！\n",
      "你們三個家夥這麽能打，外面有的是活幹\n",
      "去賣武啊！笨蛋\n",
      "還裝孫子，窩在這里幹什麽啊？\n",
      "包租婆，別這麽說\n",
      "他們應該有苦衷的\n",
      "家家都有本難念的經\n",
      "其實我們也不想連累你\n",
      "你知道就好了，得罪了斧頭幫\n",
      "我們還有好日子過嗎？還不快點給我滾\n",
      "包租婆有點過份了\n",
      "你還好嗎？\n",
      "三位師父\n",
      "我家沒有東西送給你們\n",
      "這是一點點心意\n",
      "謝謝你救我們\n",
      "等上墳的時候再哭吧，在這演戲\n",
      "你怎樣這樣鐵石心腸\n",
      "喲，還敢頂嘴？\n",
      "你以為會點三腳貓功夫就不是兔子？\n",
      "會功夫也不是罪啊\n",
      "你一天是兔子，就一輩子是兔子\n",
      "你看你里邊穿條紅底褲，白里透紅\n",
      "兜緊了沒有？當心漏出來啊\n",
      "穿紅底褲也有罪嗎？\n",
      "你有事就躲起來，沒事就趕人走\n",
      "要不是他們三個，我們可就慘了\n",
      "你做人講不講道理，啊？\n",
      "好！我就跟你們講道理\n",
      "你們三個家夥欠我三個月房租\n",
      "三三得九，九十塊，拿來\n",
      "有錢給錢，沒錢就收拾包袱，滾\n",
      "不用怕，我幫他們給\n",
      "齙牙珍，你做出頭鳥是吧？\n",
      "我現在就做出頭鳥了，行不行？\n",
      "肥婆！\n",
      "八婆！\n",
      "包租婆，你不要這麽暴躁\n",
      "欠著我房租不交，都吃了熊心豹子膽了\n",
      "怎麽可以這樣呢\n",
      "人家剛才救了你\n",
      "造反了！\n",
      "跟我比嗓門，找死啊\n",
      "那肥婆像殺豬一樣鬼叫，死有余辜\n",
      "學著點\n",
      "為什麽？\n",
      "什麽為什麽？\n",
      "你來扔\n",
      "我扔啊？\n",
      "快點！\n",
      "不好意思，你覺得怎麽樣？\n",
      "我覺得你可以往前一點，再瞄準一點\n",
      "好不好？\n",
      "好！\n",
      "誰扔的刀把？\n",
      "刀把？\n",
      "又多了一把，刀把呢？\n",
      "我怎麽知道扔到哪去了你\n",
      "難道是同一把？沒理由啊\n",
      "不要！\n",
      "不好意思\n",
      "你是不是有話想說？\n",
      "是啊，我辦點重要事情先，再聯絡\n",
      "糟，被發現了\n",
      "不要過來啊\n",
      "不用怕！蛇最喜歡聽音樂\n",
      "我一吹口哨，他就不會咬人了\n",
      "我不會再信你了\n",
      "再信一次\n",
      "又是你這個王八蛋\n",
      "別看了別看了，大家都散開了，都回去吧\n",
      "這個人什麽都亂說的\n",
      "分頭走！\n",
      "走？\n",
      "在這幹什麽啊你？\n",
      "找你咯，你不是受傷了嗎？\n",
      "我沒事啊！\n",
      "你怎麽每次受傷都會沒事的？\n",
      "我不知道\n",
      "你看哪位醫生啊？\n",
      "我也完全不記得了\n",
      "也好\n",
      "記憶是痛苦的根源\n",
      "你能不記得，算是福氣了\n",
      "聽你這麽說，感觸良多\n",
      "問君能有幾多愁\n",
      "恰似一江春水向東流\n",
      "走開啊！\n",
      "讓一讓，拜托\n",
      "打爆你的眼鏡！\n",
      "你看那兩個四眼崽\n",
      "清明還沒到，就背著個棺材板到處走\n",
      "腦袋進水\n",
      "別說是我逼你們走啊，咱們照老規矩來\n",
      "讓菩薩做決定\n",
      "請各位鄉親父老作證\n",
      "上簽就留，下簽就走\n",
      "兩位請用茶\n",
      "這次有勞兩位這麽專業人士到這兒來\n",
      "這個我們全都明白\n",
      "洪家鐵線拳\n",
      "五郎八卦棍，十二路譚腿\n",
      "全部在這里\n",
      "是比較棘手\n",
      "之前他們都是一流高手\n",
      "只因厭倦了武林爭鬥而退出江湖\n",
      "這份工作，對我們來說非常具有挑戰性\n",
      "這個就叫專業\n",
      "當然了，殺手排行榜第一位\n",
      "物超所值，貴點也值得\n",
      "錯！第一位是終極殺人王\n",
      "火雲邪神\n",
      "他太醉心於武功\n",
      "以至於練功走火入魔\n",
      "聽說，現在已經住進精神病醫院了\n",
      "那排行榜第一位始終還是兩位\n",
      "嚴格來說我們只不過是賣唱的\n",
      "一曲肝腸斷\n",
      "天涯何處覓知音？\n",
      "餵，好詩啊！是不是？\n",
      "一會兒就要分手了\n",
      "不知道以後有沒有機會再見面\n",
      "原來大家都是同道中人\n",
      "早知道，就不會這麽寂寞了\n",
      "不如趁這個最後機會\n",
      "我們來切磋一下\n",
      "別逗了，還有很多行李沒收拾呢\n",
      "我也是說說而已\n",
      "對\n",
      "十二路譚腿攻守並重，名不虛傳\n",
      "鐵線拳剛中有柔，可謂拳中之尊！\n",
      "五郎八卦棍，千變萬化，高深莫測！\n",
      "後會有期\n",
      "又有口紅\n",
      "炒菜咧，火一定要這樣\n",
      "這樣，炒菜一定要大，知道嗎？\n",
      "你給我站住，再跑，再跑，我打死你\n",
      "不好意思，今天不做生意了\n",
      "做件衣服很快的\n",
      "我們要搬家了\n",
      "這塊布料是上品的\n",
      "你挺識貨的\n",
      "這塊布料的藝術成分很高\n",
      "有多高？\n",
      "三、四樓那麽高了\n",
      "得罪斧頭幫就是嫌命長\n",
      "先打死這三個王八蛋\n",
      "再拿他們這去做煙花巷\n",
      "叫你別擋著我！\n",
      "什麽事？\n",
      "好！\n",
      "叫你別擋著我\n",
      "要命啊，叫那三個家夥趕快走\n",
      "又打到這兒來了\n",
      "不是吧？\n",
      "是啊\n",
      "有沒有搞錯，在這里打架？\n",
      "打爛了東西誰賠？\n",
      "對不起…沒事沒事\n",
      "你們吵夠了沒啊！\n",
      "現在幾點了？不用睡覺了？！\n",
      "死肥婆，你歇者吧你\n",
      "我哪里說的不對了？你們吵的沒完沒了\n",
      "對不起…沒事沒事\n",
      "別再擋了我看戲啊\n",
      "撐住\n",
      "別再吵了！\n",
      "給條活路走行不行？不要趕盡殺絕\n",
      "還有高手？\n",
      "這就是獅吼功嗎！\n",
      "誰人打的太極拳？\n",
      "獅吼功？太極拳？\n",
      "治好了也浪費湯藥，算了\n",
      "不好了，琛哥，快開車！\n",
      "開車啊\n",
      "大哥\n",
      "大什麽哥！你有沒有公德心啊？\n",
      "又吵又鬧的，街坊們不用睡覺了？\n",
      "人家明天還要上班哪，滾開！\n",
      "你們這些敗類！\n",
      "沒用的，我活不了多久了\n",
      "我能夠見到你們這些\n",
      "真正的高手\n",
      "我也不枉此生\n",
      "別這麽說了，阿鬼\n",
      "我們只是想安享晚年的小市民\n",
      "平凡是福\n",
      "高手這個名實在是不想再背負了\n",
      "你們兩個這麽厲害\n",
      "早點出手的話\n",
      "他們就不會死得那麽慘了\n",
      "就像阿鬼說的，家家有本難念的經\n",
      "當年為了比武，親眼看到兒子被人打死\n",
      "冤冤相報何時了，望各位體諒！\n",
      "既然這樣，你們把功夫傳給我\n",
      "讓我成為絕世高手，為他們報仇！\n",
      "要成為絕世高手，並非一朝一夕\n",
      "除非是天生的武學奇才\n",
      "但是這種人…是萬中無一\n",
      "很明顯，我就是這種人\n",
      "看來，他不是\n",
      "各位！我們倆夫妻曾經發過毒誓\n",
      "不再顯露武功\n",
      "但今天不出手也出手了\n",
      "為了安全，我們盡快離開這里吧\n",
      "能力越大，責任就越大\n",
      "你避不了的\n",
      "阿鬼，你傷得那麽重，不要動氣啊\n",
      "阿鬼，你還是說中文好了\n",
      "阿鬼\n",
      "四眼崽，我認得你\n",
      "看來這位先生對戴眼鏡人士\n",
      "有很深的成見\n",
      "沒錯，尤其是金絲眼鏡\n",
      "我身為一個文員，戴金絲眼鏡\n",
      "是很合理，也很合邏輯的\n",
      "我戴得好看，為什麽你一定要針對我？\n",
      "幫忙！\n",
      "幫忙是吧？地痞是吧？\n",
      "龍形是吧？虎形是吧？\n",
      "你下車\n",
      "我打爆你的眼鏡，你下車\n",
      "你相不相信我打爆他的眼鏡？\n",
      "你發誓\n",
      "發誓啊\n",
      "看不起我啊你？\n",
      "剛才叫你幫忙，你幹什麽了？\n",
      "汪什麽汪啊\n",
      "這麽囂張，活該被人打啊你\n",
      "這麽久以來，殺人放火打劫強奸非禮\n",
      "沒有一次你能做的到\n",
      "就因為你這頭肥豬礙手礙腳\n",
      "教而不善，爛泥扶不上墻\n",
      "跟我來\n",
      "打劫，錢擺在哪邊？\n",
      "擺在哪邊？說\n",
      "看什麽？看不起我啊！\n",
      "我殺人不眨眼！錢擺在哪邊？\n",
      "說！\n",
      "錢在這里\n",
      "放開那女孩！\n",
      "一個傻子，一個啞巴\n",
      "死一邊去吧！\n",
      "你不要再跟著我了！我遲早會被你累死\n",
      "就說你是爛泥扶不上墻\n",
      "回家養豬去吧\n",
      "打死你！\n",
      "那個誰！那個誰！\n",
      "來，這錢拿去裝身\n",
      "從今天起，你就是我們斧頭幫的了\n",
      "不會吧？\n",
      "沒錯！有個老朋友等著你呢\n",
      "琛哥！\n",
      "我一看你的樣子\n",
      "就知道你除了好事以外，什麽都敢做\n",
      "是啊！\n",
      "你只欠一個機會\n",
      "是啊！\n",
      "有件事找你幫忙\n",
      "赴湯蹈火，琛哥！\n",
      "不正常人類研究中心\n",
      "這什麽啊？\n",
      "精神病院\n",
      "報告警司！\n",
      "哇，有軍隊啊！\n",
      "那些是童子軍！\n",
      "還有坦克車！\n",
      "關你什麽事啊，鎮定點\n",
      "趁童子軍換班的時候\n",
      "你有五分鐘的時間\n",
      "跟著地圖指示的箭頭\n",
      "到地下室最後那個房間\n",
      "把門鎖打開，將里面那個人帶出來\n",
      "就這麽簡單\n",
      "家夥都在這，走\n",
      "餵，那你們呢？\n",
      "我們幫你把風嘛\n",
      "只有五分鐘，快點\n",
      "終極第一殺人王火雲邪神\n",
      "果然有派頭\n",
      "只是個虛名而已\n",
      "廢話少說了，我們想請你幫忙殺兩個人\n",
      "開個價吧\n",
      "開什麽價？\n",
      "我是殺了很多人\n",
      "就是想找個能打贏我的人，最後發現\n",
      "沒人是我的對手才躲起來清凈一下\n",
      "如果有對手的話，我早就出來了\n",
      "哪有人困得住我啊\n",
      "告訴你，如果有絕世高手\n",
      "我免費見一個殺一個！\n",
      "有沒有？\n",
      "是真正的絕世高手啊\n",
      "正合你胃口啊，邪神先生\n",
      "不過不知道你介不介意先露兩手呢？\n",
      "不是不相信你啊，我們大家想開開眼界\n",
      "你們這些廢物，根本沒資格要我出手\n",
      "真的假的？\n",
      "內衣褲拖鞋是挺標新立異的\n",
      "如果能幫他整理一下他應該會有前途\n",
      "去你媽的，是不是救錯人了\n",
      "絕對沒有\n",
      "我發誓絕對是照著吩咐去做的\n",
      "火雲邪神，您耍兩招讓大家開開眼界\n",
      "不要讓我難做\n",
      "神經病！\n",
      "老伯，這是什麽？\n",
      "沙包一樣大的拳頭見過沒有你啊？\n",
      "不要逼我出手啊你\n",
      "我發起瘋來，連自己都怕的\n",
      "是嗎？出手吧\n",
      "怎麽樣？沒事吧他？\n",
      "老頭，你很能打是嗎？\n",
      "用力！\n",
      "用力！\n",
      "用力！\n",
      "打人都沒力氣，還說是黑社會？\n",
      "洋槍\n",
      "天下武功，無堅不破，唯快不破\n",
      "火雲邪神武功蓋世\n",
      "斧頭幫全體同仁向邪神敬禮！\n",
      "絕世高手就在這里\n",
      "看來，只有當年終極殺人王火雲邪神\n",
      "才有這樣的煞氣\n",
      "這種氣勢\n",
      "難道就是人稱神雕俠侶的…？\n",
      "楊過\n",
      "小龍女\n",
      "久仰大名\n",
      "今天我們來\n",
      "是和斧頭幫算帳的，與其他人無關\n",
      "你當初殺了我，不就什麽事都沒了\n",
      "今天才來算帳，那不是自投羅網？\n",
      "留你狗命多活兩天，別那麽囂張\n",
      "我這份大禮，你今天收定了\n",
      "送鐘？\n",
      "今天有邪神在這，看是誰給誰送終！\n",
      "你做出頭鳥是吧？\n",
      "不，不要誤會\n",
      "我只是想打死兩位或者被兩位打死\n",
      "老婆，你怎麽看？\n",
      "自古正邪不兩立\n",
      "我不入地獄，誰入地獄？\n",
      "既然是這樣，來啊\n",
      "好啊\n",
      "來啊！\n",
      "用點力，我還行\n",
      "力量夠了，不過準確度差點\n",
      "獅吼功？\n",
      "等等！\n",
      "想不到獅吼功還有一招大喇叭\n",
      "小弟甘拜下風\n",
      "他們好像動不了！\n",
      "絕對是！趁他虛要他命\n",
      "你來！\n",
      "我想吐…我要去看醫生\n",
      "吃屎吧你！\n",
      "你！過來\n",
      "K他！\n",
      "好！\n",
      "打頭！\n",
      "當然了！\n",
      "照頭打下去！\n",
      "好！\n",
      "揚名立萬！\n",
      "來啊！\n",
      "打他！\n",
      "打他啊！\n",
      "打他媽的！\n",
      "打啊！\n",
      "打他！\n",
      "打他啊！\n",
      "打他媽的！\n",
      "你到底是想我打他本人還是打他的媽啊？\n",
      "你搞得我好亂啊\n",
      "哇！沙包這麽大的拳頭，怎麽練的你？\n",
      "為什麽要打我？\n",
      "人呢？去哪兒了？\n",
      "你有沒有搞錯，居然讓他們跑了？\n",
      "沒有人可以在我手上跑掉的\n",
      "為什麽是他救了我們？\n",
      "年輕人，行差踏錯一定會了\n",
      "能夠懸崖勒馬，還有的救\n",
      "你看他！被人打得他老媽都不認得了\n",
      "你還有什麽心願？你說吧\n",
      "餵！大哥\n",
      "你還是寫中文吧\n",
      "不懂啊，餵！\n",
      "耶！沒有啊\n",
      "他能挨到現在，簡直就是奇跡\n",
      "是我們的藥神奇吧\n",
      "藥只不過是輔助\n",
      "關鍵是他本身的體質\n",
      "全身骨折，經脈盡斷，不僅沒有死\n",
      "還在這麽短時間自動複原\n",
      "平常人根本就不可能\n",
      "除非他是…\n",
      "什麽味？\n",
      "受傷不要抽煙了\n",
      "這里交給我\n",
      "沒理由啊\n",
      "想不到火雲邪神間接打通了他任督二脈\n",
      "將他的潛能逼了出來\n",
      "其實，我們早就應該想到\n",
      "他就是萬中無一的絕世高手\n",
      "有這樣的事？\n",
      "好啊，原來你這個叛徒還沒死\n",
      "兄弟們，砍死他！\n",
      "踩腳指\n",
      "小孩子打架才用這招\n",
      "如果我們的兒子沒死\n",
      "也該有他這麽大了\n",
      "如果他能好好讀書的話\n",
      "我看他將來不是做醫生就是做律師\n",
      "不過看他的樣子應該當武師\n",
      "不錯，來啊\n",
      "子彈我都抓得住\n",
      "啊！居然是昆侖派的蛤蟆功\n",
      "這下槽了！\n",
      "老公\n",
      "你記不記得有一招從天而降的掌法？\n",
      "是已經失傳的如來神掌\n",
      "投降了！\n",
      "這是什麽掌法？\n",
      "想學啊你？我教你\n",
      "我輸了\n",
      "那兩個你認不認識啊\n",
      "叫他們不要把鼻涕抹在玻璃上\n",
      "你們兩個把褲子穿上\n",
      "你們是不是買啊？不買不要舔哪\n",
      "小弟，看你的骨骼精奇\n",
      "是萬中無一的練武奇材\n",
      "維護世界和平就靠你了\n",
      "我這里有本秘笈\n",
      "我看與你有緣，就十塊錢賣給你了\n",
      "等等！\n",
      "這本不合適？還有\n"
     ]
    }
   ],
   "source": [
    "for line in ori_files[1][0]:\n",
    "    line = line.strip()\n",
    "    if line.isdigit():\n",
    "        pass\n",
    "    elif line.find('-->') > 0:\n",
    "        pass\n",
    "    elif len(line) == 0:\n",
    "        pass\n",
    "    else: \n",
    "        if chardet.detect(line)['encoding'] is not None:\n",
    "            print line.decode(chardet.detect(line)['encoding']).encode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utf-8\n",
      "utf-8\n",
      "windows-1252\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n",
      "ascii\n",
      "utf-8\n",
      "utf-8\n",
      "utf-8\n"
     ]
    }
   ],
   "source": [
    "with open('../input.csv', 'w+') as f:\n",
    "    f.seek(0)\n",
    "    for data,encoding in ori_files:\n",
    "        for line in data:\n",
    "            line = line.strip()\n",
    "            if len(line) > 0:\n",
    "                if line.isdigit():\n",
    "                    pass\n",
    "                elif line.find('-->') > 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    encoding = chardet.detect(line)['encoding']\n",
    "                    if encoding is not None:\n",
    "                        try:\n",
    "                            f.write(line.decode(encoding).encode(\"utf-8\") + '\\n')\n",
    "                        except:\n",
    "                            pass\n",
    "                    else:\n",
    "                        pass\n",
    "        print encoding\n",
    "    f.truncate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = {'0','1','2','3','4','5','6','7','8','9','-','+','\\n'}   \n",
    "def cuttext_by_server(text,stop_sc):\n",
    "    retry = 3\n",
    "    for _ in range(retry) :\n",
    "        try:\n",
    "            stop_word = stop_sc #= stop_sc.value\n",
    "            url = 'http://localhost:11200'\n",
    "            req = urllib2.Request(url, text.encode('utf8'))\n",
    "            response = urllib2.urlopen(req,timeout=120)\n",
    "            terms = response.read().split(\" \")\n",
    "            r = []\n",
    "            for i in terms:\n",
    "                if len(i) <=3 or i[0] in stop or i in stop_word: \n",
    "                    continue\n",
    "                r.append(i)\n",
    "            return r\n",
    "        except :\n",
    "            import sys\n",
    "            print \"Unexpected error:\", sys.exc_info()\n",
    "            time.sleep(1)\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\xe4\\xbb\\x8a\\xe5\\xa4\\xa9', '\\xe5\\xa4\\xa9\\xe6\\xb0\\xa3', '\\xe6\\xb7\\xa1\\xe6\\xb0\\xb4']\n"
     ]
    }
   ],
   "source": [
    "aa = cuttext_by_server(u'今天天氣很好想去淡水玩',{})\n",
    "print aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成1000筆\n",
      "完成1000筆\n",
      "完成1000筆\n",
      "完成1000筆\n",
      "完成1000筆\n",
      "完成1000筆\n",
      "完成1000筆\n",
      "完成1000筆\n",
      "完成1000筆\n",
      "完成1000筆\n",
      "完成1000筆\n",
      "完成1000筆\n",
      "完成1000筆\n",
      "完成1000筆\n",
      "完成1000筆\n"
     ]
    }
   ],
   "source": [
    "aaaa = []\n",
    "count = 0\n",
    "fw = open('cut_result.csv','w+')\n",
    "with open('../input.csv', 'r') as f:\n",
    "    for line in f:\n",
    "        count = count + 1\n",
    "        try:\n",
    "            fw.write(' '.join(cuttext_by_server(unicode(line, 'utf-8'), {})) + '\\n')\n",
    "            if not count % 1000:\n",
    "                print '完成1000筆'\n",
    "        except:\n",
    "            aaaa.append(line)\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aaaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import itertools\n",
    "import shutil\n",
    "from textblob import TextBlob\n",
    "from textblob import WordList\n",
    "import time\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "import random\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "import sys\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "unknown_token = \"UNKNOWN_TOKEN\"\n",
    "sentence_start_token = \"SENTENCE_START\"\n",
    "sentence_end_token = \"SENTENCE_END\"\n",
    "number_of_iterations = 20 #max number of iterations/epochs you want to run for. \n",
    "start_validating_at_iteration = 0 #which iteration to start checking for overfitting\n",
    "patience = 10 #number of times where validation loss has to rise before quitting algorithm\n",
    "hidden_variables = 256 #number of hidden variables in all layers, keep this betwen 256 and 512\n",
    "dropout = 0.5 #the dropout between each layer -- recommendation is 0.5\n",
    "embedding_size = 128 #this should be 128 or 256 or 512\n",
    "hidden_size = 128\n",
    "batch_size = 1024\n",
    "decoder_layers = 3 #number of lstm layers for decoding -- try 4, maybe eventually up to 8. \n",
    "time_steps = 20 #number to pad the vector by. Should be the max number of words in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"cut_result.csv\",'r') as f:\n",
    "    _data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for each in _data[:100000]:\n",
    "    each = each.decode('utf-8')\n",
    "    each = each.strip()\n",
    "    if len(each) > 0:\n",
    "        data.append(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [\"%s %s %s\" % (sentence_start_token, x, sentence_end_token) for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenized_sentences = [each.split() for each in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_freq = nltk.FreqDist(itertools.chain(*tokenized_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13004 unique words tokens.\n"
     ]
    }
   ],
   "source": [
    "print (\"Found %d unique words tokens.\" % len(word_freq.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = word_freq.most_common(vocabulary_size-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_to_word = ['padzero']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "the increased vocab is\n",
      "10002\n"
     ]
    }
   ],
   "source": [
    "print('Building model...')\n",
    "\n",
    "increased_vocab = (int(len(vocab))+2+1)\n",
    "\n",
    "print ('the increased vocab is')\n",
    "print increased_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Using vocabulary size 10000.\n",
      "The least frequent word in our vocabulary is '宣佈' and appeared 1 times.\n",
      "\n",
      "Example sentence: 'SENTENCE_START 白粥 油條 公公 SENTENCE_END'\n",
      "\n",
      "Example sentence after Pre-processing: '[u'SENTENCE_START', u'\\u767d\\u7ca5', 'UNKNOWN_TOKEN', 'UNKNOWN_TOKEN', u'SENTENCE_END']'\n"
     ]
    }
   ],
   "source": [
    "for x in vocab:\n",
    "    index_to_word.append(x[0]) #this is based upon frequency of word used -- nice\n",
    "\n",
    "index_to_word.append(unknown_token) #this is making the word for all unknown words here\n",
    "print '-----------------------------------------------------------------------------------------------'\n",
    "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
    "print\n",
    "print\n",
    "\n",
    "print (\"Using vocabulary size %d.\" % vocabulary_size)\n",
    "print (\"The least frequent word in our vocabulary is '%s' and appeared %d times.\" % (vocab[-1][0], vocab[-1][1]))\n",
    " \n",
    "# Replace all words not in our vocabulary with the unknown token\n",
    "for i, sent in enumerate(tokenized_sentences):\n",
    "    tokenized_sentences[i] = [w if w in word_to_index else unknown_token for w in sent]\n",
    "print (\"\\nExample sentence: '%s'\" % sentences[0])\n",
    "\n",
    "print (\"\\nExample sentence after Pre-processing: '%s'\" % tokenized_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * \n"
     ]
    }
   ],
   "source": [
    "encoder_input_array = ([[word_to_index[w] for w in sent] for sent in tokenized_sentences[1:-1]])\n",
    "#the ::-1 is to reverse the list\n",
    "encoder_input = sequence.pad_sequences(encoder_input_array, maxlen=time_steps)\n",
    "\n",
    "\n",
    "decoder_prev_array = ([[word_to_index[w] for w in sent] for sent in tokenized_sentences[:-1]])[:-1]\n",
    "decoder_prev_input = sequence.pad_sequences(decoder_prev_array, maxlen=time_steps)\n",
    "\n",
    "decoder_prev_target_array = ([[word_to_index[w] for w in sent[1:]] for sent in tokenized_sentences[:-1]])[:-1]\n",
    "decoder_prev_target = sequence.pad_sequences(decoder_prev_target_array, maxlen=time_steps)\n",
    "\n",
    "\n",
    "decoder_next_array = ([[word_to_index[w] for w in sent] for sent in tokenized_sentences[1:]])[1:]\n",
    "decoder_next_input = sequence.pad_sequences(decoder_next_array, maxlen=time_steps)\n",
    "\n",
    "decoder_next_target_array = ([[word_to_index[w] for w in sent[1:]] for sent in tokenized_sentences[1:]])[1:]\n",
    "decoder_next_target = sequence.pad_sequences(decoder_next_target_array, maxlen=time_steps)\n",
    "print '* '*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    1 2382   15    2]\n",
      "padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero SENTENCE_START 總該 知道 SENTENCE_END\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print encoder_input[T]\n",
    "for each in encoder_input[T]:\n",
    "    print index_to_word[each],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    1 1539 3141    2]\n",
      "padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero SENTENCE_START many questions SENTENCE_END\n"
     ]
    }
   ],
   "source": [
    "print decoder_prev_input[T]\n",
    "for each in decoder_prev_input[T]:\n",
    "    print index_to_word[each],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0   74  113 3783    2]\n",
      "padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero padzero should know reason SENTENCE_END\n"
     ]
    }
   ],
   "source": [
    "print decoder_next_target[T]\n",
    "for each in decoder_next_target[T]:\n",
    "    print index_to_word[each],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, merge\n",
    "from keras.layers.core import Activation, TimeDistributedDense, RepeatVector, Dropout, Dense, Reshape, Lambda\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import random, sys\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.regularizers import l2, activity_l2, l1, activity_l1\n",
    "from keras.layers.convolutional import Cropping1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tensorboard = TensorBoard(log_dir=\"./logs\")\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0, clipvalue=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.array([[1,1],[2,2]])\n",
    "bb = np.array([[1,2],[3,4],[5,6],[7,8]])\n",
    "bb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [2, 2],\n",
       "       [1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((aa,bb))[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x120db4a50>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main_input = Input(shape=(20,))\n",
    "\n",
    "\n",
    "decoder_prev_inputs = Input(shape=(20,), name='decoder_prev_input')\n",
    "decoder_next_inputs = Input(shape=(20,), name='decoder_next_input')\n",
    "\n",
    "embedding = np.random.random((increased_vocab, embedding_size))\n",
    "shared_embedding_layer = Embedding(increased_vocab, embedding_size, input_length=time_steps,\n",
    "                                   mask_zero=True,weights=[embedding])\n",
    "\n",
    "shared_embedding_layer_unmask = Embedding(increased_vocab, embedding_size, input_length=time_steps,\n",
    "                                   mask_zero=False,weights=[embedding])\n",
    "\n",
    "main_embd = shared_embedding_layer(main_input)\n",
    "prev_embd = shared_embedding_layer(decoder_prev_inputs)\n",
    "next_embd = shared_embedding_layer(decoder_next_inputs)\n",
    "\n",
    "\n",
    "\n",
    "encoder = GRU(hidden_size, activation='relu', return_sequences=False,\n",
    "                                  W_regularizer=l1(0.5) )(main_embd)\n",
    "encoder = Reshape((1,hidden_size))(encoder)\n",
    "\n",
    "#prev_embd = Reshape((1, 5120))(prev_embd)\n",
    "#next_embd = Reshape((1, 5120))(next_embd)\n",
    "#prev_crop = Cropping1D(cropping=(1, 256))(prev_embd)\n",
    "\n",
    "#prev_embd = Reshape((20, 256))(prev_crop)\n",
    "#next_embd = Reshape((20, 256))(next_embd)\n",
    "\n",
    "#prev_embd = Lambda(lambda x,: x[1:], output_shape=(19,256))(prev_embd)\n",
    "#next_embd = Lambda(lambda x,: x[1:], output_shape=(19,256))(next_embd)\n",
    "\n",
    "x_prev = merge([encoder, prev_embd],  mode=lambda x: x[0] - x[1], output_shape=(21,hidden_size))\n",
    "x_next = merge([encoder, next_embd], mode=lambda x: x[0] - x[1], output_shape=(21,hidden_size))\n",
    "\n",
    "decoder_prev = GRU(hidden_size, activation='relu', return_sequences=False,  W_regularizer=l1(0.5))(x_prev)\n",
    "decoder_next = GRU(hidden_size, activation='relu', return_sequences=False,  W_regularizer=l1(0.5))(x_next)\n",
    "\n",
    "decoder_prev_outputs = Dense(output_dim=20, activation=\"softmax\")(decoder_prev)\n",
    "decoder_next_outputs = Dense(output_dim=20, activation=\"softmax\")(decoder_next)\n",
    "\n",
    "\n",
    "sequence_autoencoder = Model(input=[main_input,decoder_prev_inputs, decoder_next_inputs], output=[decoder_prev_outputs, decoder_next_outputs])\n",
    "\n",
    "sequence_autoencoder.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"483pt\" viewBox=\"0.00 0.00 566.57 483.00\" width=\"567pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-479 562.566,-479 562.566,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 4997875920 -->\n",
       "<g class=\"node\" id=\"node1\"><title>4997875920</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 128.362,-474.5 128.362,-438.5 0,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"64.1812\" y=\"-452.3\">input_2: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4846209616 -->\n",
       "<g class=\"node\" id=\"node4\"><title>4846209616</title>\n",
       "<polygon fill=\"none\" points=\"163.11,-365.5 163.11,-401.5 327.252,-401.5 327.252,-365.5 163.11,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.181\" y=\"-379.3\">embedding_3: Embedding</text>\n",
       "</g>\n",
       "<!-- 4997875920&#45;&gt;4846209616 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>4997875920-&gt;4846209616</title>\n",
       "<path d=\"M107.535,-438.494C132.871,-428.555 165.046,-415.934 191.916,-405.394\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"193.522,-408.524 201.554,-401.614 190.966,-402.007 193.522,-408.524\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4846208016 -->\n",
       "<g class=\"node\" id=\"node2\"><title>4846208016</title>\n",
       "<polygon fill=\"none\" points=\"146.41,-438.5 146.41,-474.5 343.952,-474.5 343.952,-438.5 146.41,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.181\" y=\"-452.3\">decoder_prev_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4846208016&#45;&gt;4846209616 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>4846208016-&gt;4846209616</title>\n",
       "<path d=\"M245.181,-438.313C245.181,-430.289 245.181,-420.547 245.181,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"248.681,-411.529 245.181,-401.529 241.681,-411.529 248.681,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4846207440 -->\n",
       "<g class=\"node\" id=\"node3\"><title>4846207440</title>\n",
       "<polygon fill=\"none\" points=\"361.796,-438.5 361.796,-474.5 558.566,-474.5 558.566,-438.5 361.796,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"460.181\" y=\"-452.3\">decoder_next_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4846207440&#45;&gt;4846209616 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>4846207440-&gt;4846209616</title>\n",
       "<path d=\"M408.683,-438.494C378.061,-428.381 339.026,-415.491 306.777,-404.841\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"307.597,-401.426 297.004,-401.614 305.402,-408.073 307.597,-401.426\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4464191184 -->\n",
       "<g class=\"node\" id=\"node5\"><title>4464191184</title>\n",
       "<polygon fill=\"none\" points=\"202.376,-292.5 202.376,-328.5 287.986,-328.5 287.986,-292.5 202.376,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.181\" y=\"-306.3\">gru_4: GRU</text>\n",
       "</g>\n",
       "<!-- 4846209616&#45;&gt;4464191184 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>4846209616-&gt;4464191184</title>\n",
       "<path d=\"M245.181,-365.313C245.181,-357.289 245.181,-347.547 245.181,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"248.681,-338.529 245.181,-328.529 241.681,-338.529 248.681,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4843493072 -->\n",
       "<g class=\"node\" id=\"node7\"><title>4843493072</title>\n",
       "<polygon fill=\"none\" points=\"127.974,-146.5 127.974,-182.5 236.389,-182.5 236.389,-146.5 127.974,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"182.181\" y=\"-160.3\">merge_3: Merge</text>\n",
       "</g>\n",
       "<!-- 4846209616&#45;&gt;4843493072 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>4846209616-&gt;4843493072</title>\n",
       "<path d=\"M224.132,-365.342C213.492,-355.67 201.175,-342.781 193.181,-329 168.207,-285.947 167.589,-268.56 172.181,-219 172.978,-210.4 174.481,-201.12 176.084,-192.743\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"179.556,-193.231 178.122,-182.734 172.697,-191.834 179.556,-193.231\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4843360976 -->\n",
       "<g class=\"node\" id=\"node8\"><title>4843360976</title>\n",
       "<polygon fill=\"none\" points=\"267.974,-146.5 267.974,-182.5 376.389,-182.5 376.389,-146.5 267.974,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322.181\" y=\"-160.3\">merge_4: Merge</text>\n",
       "</g>\n",
       "<!-- 4846209616&#45;&gt;4843360976 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>4846209616-&gt;4843360976</title>\n",
       "<path d=\"M266.231,-365.342C276.871,-355.67 289.187,-342.781 297.181,-329 322.014,-286.191 324.741,-226.918 323.872,-192.752\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"327.363,-192.454 323.487,-182.594 320.368,-192.719 327.363,-192.454\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4846209808 -->\n",
       "<g class=\"node\" id=\"node6\"><title>4846209808</title>\n",
       "<polygon fill=\"none\" points=\"181.396,-219.5 181.396,-255.5 308.966,-255.5 308.966,-219.5 181.396,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"245.181\" y=\"-233.3\">reshape_2: Reshape</text>\n",
       "</g>\n",
       "<!-- 4464191184&#45;&gt;4846209808 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>4464191184-&gt;4846209808</title>\n",
       "<path d=\"M245.181,-292.313C245.181,-284.289 245.181,-274.547 245.181,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"248.681,-265.529 245.181,-255.529 241.681,-265.529 248.681,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4846209808&#45;&gt;4843493072 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>4846209808-&gt;4843493072</title>\n",
       "<path d=\"M229.931,-219.313C222.192,-210.592 212.652,-199.84 204.139,-190.246\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"206.546,-187.686 197.291,-182.529 201.31,-192.332 206.546,-187.686\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4846209808&#45;&gt;4843360976 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>4846209808-&gt;4843360976</title>\n",
       "<path d=\"M263.821,-219.313C273.563,-210.33 285.641,-199.193 296.277,-189.386\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"298.734,-191.881 303.713,-182.529 293.989,-186.735 298.734,-191.881\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4816768272 -->\n",
       "<g class=\"node\" id=\"node9\"><title>4816768272</title>\n",
       "<polygon fill=\"none\" points=\"139.376,-73.5 139.376,-109.5 224.986,-109.5 224.986,-73.5 139.376,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"182.181\" y=\"-87.3\">gru_5: GRU</text>\n",
       "</g>\n",
       "<!-- 4843493072&#45;&gt;4816768272 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>4843493072-&gt;4816768272</title>\n",
       "<path d=\"M182.181,-146.313C182.181,-138.289 182.181,-128.547 182.181,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"185.681,-119.529 182.181,-109.529 178.681,-119.529 185.681,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 4999164944 -->\n",
       "<g class=\"node\" id=\"node10\"><title>4999164944</title>\n",
       "<polygon fill=\"none\" points=\"279.376,-73.5 279.376,-109.5 364.986,-109.5 364.986,-73.5 279.376,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322.181\" y=\"-87.3\">gru_6: GRU</text>\n",
       "</g>\n",
       "<!-- 4843360976&#45;&gt;4999164944 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>4843360976-&gt;4999164944</title>\n",
       "<path d=\"M322.181,-146.313C322.181,-138.289 322.181,-128.547 322.181,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"325.681,-119.529 322.181,-109.529 318.681,-119.529 325.681,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 5001347728 -->\n",
       "<g class=\"node\" id=\"node11\"><title>5001347728</title>\n",
       "<polygon fill=\"none\" points=\"130.055,-0.5 130.055,-36.5 234.307,-36.5 234.307,-0.5 130.055,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"182.181\" y=\"-14.3\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 4816768272&#45;&gt;5001347728 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>4816768272-&gt;5001347728</title>\n",
       "<path d=\"M182.181,-73.3129C182.181,-65.2895 182.181,-55.5475 182.181,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"185.681,-46.5288 182.181,-36.5288 178.681,-46.5289 185.681,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 5012108944 -->\n",
       "<g class=\"node\" id=\"node12\"><title>5012108944</title>\n",
       "<polygon fill=\"none\" points=\"270.055,-0.5 270.055,-36.5 374.307,-36.5 374.307,-0.5 270.055,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"322.181\" y=\"-14.3\">dense_4: Dense</text>\n",
       "</g>\n",
       "<!-- 4999164944&#45;&gt;5012108944 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>4999164944-&gt;5012108944</title>\n",
       "<path d=\"M322.181,-73.3129C322.181,-65.2895 322.181,-55.5475 322.181,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"325.681,-46.5288 322.181,-36.5288 318.681,-46.5289 325.681,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(SVG(model_to_dot(sequence_autoencoder).create(prog='dot', format='svg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "decoder_prev_input (InputLayer)  (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "decoder_next_input (InputLayer)  (None, 20)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 20, 128)       1280256     input_2[0][0]                    \n",
      "                                                                   decoder_prev_input[0][0]         \n",
      "                                                                   decoder_next_input[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "gru_4 (GRU)                      (None, 128)           98688       embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)              (None, 1, 128)        0           gru_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                  (None, 21, 128)       0           reshape_2[0][0]                  \n",
      "                                                                   embedding_3[1][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_4 (Merge)                  (None, 21, 128)       0           reshape_2[0][0]                  \n",
      "                                                                   embedding_3[2][0]                \n",
      "____________________________________________________________________________________________________\n",
      "gru_5 (GRU)                      (None, 128)           98688       merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "gru_6 (GRU)                      (None, 128)           98688       merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 20)            2580        gru_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 20)            2580        gru_6[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 1581480\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sequence_autoencoder.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14584, 20)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_next_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11667 samples, validate on 2917 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 2621440 values, but the requested shape requires a multiple of 2688\n\t [[Node: Reshape_37 = Reshape[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](add_122, pack_17)]]\nCaused by op u'Reshape_37', defined at:\n  File \"/Users/wayne/anaconda2/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/wayne/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-132-3a80c42cd07a>\", line 38, in <module>\n    decoder_next = GRU(hidden_size, activation='relu', return_sequences=False,  W_regularizer=l1(0.5))(x_next)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 517, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 571, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 155, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/layers/recurrent.py\", line 219, in call\n    preprocessed_input = self.preprocess_input(x)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/layers/recurrent.py\", line 545, in preprocess_input\n    input_dim, self.output_dim, timesteps)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/layers/recurrent.py\", line 35, in time_distributed_dense\n    x = K.reshape(x, K.pack([-1, timesteps, output_dim]))\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 759, in reshape\n    return tf.reshape(x, shape)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1383, in reshape\n    name=name)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 704, in apply_op\n    op_def=op_def)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2260, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1230, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-930dbd7fcd5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                          \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                          \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                          verbose=2)\n\u001b[0m",
      "\u001b[0;32m/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1109\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wayne/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 372\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    373\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wayne/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       results = self._do_run(handle, target_list, unique_fetches,\n\u001b[0;32m--> 636\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    637\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0;31m# The movers are no longer used. Delete them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wayne/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 708\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    709\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/wayne/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 2621440 values, but the requested shape requires a multiple of 2688\n\t [[Node: Reshape_37 = Reshape[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](add_122, pack_17)]]\nCaused by op u'Reshape_37', defined at:\n  File \"/Users/wayne/anaconda2/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/Users/wayne/anaconda2/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/traitlets/config/application.py\", line 596, in launch_instance\n    app.start()\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 442, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 391, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 199, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2825, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-132-3a80c42cd07a>\", line 38, in <module>\n    decoder_next = GRU(hidden_size, activation='relu', return_sequences=False,  W_regularizer=l1(0.5))(x_next)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 517, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 571, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/engine/topology.py\", line 155, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/layers/recurrent.py\", line 219, in call\n    preprocessed_input = self.preprocess_input(x)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/layers/recurrent.py\", line 545, in preprocess_input\n    input_dim, self.output_dim, timesteps)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/layers/recurrent.py\", line 35, in time_distributed_dense\n    x = K.reshape(x, K.pack([-1, timesteps, output_dim]))\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py\", line 759, in reshape\n    return tf.reshape(x, shape)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1383, in reshape\n    name=name)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/op_def_library.py\", line 704, in apply_op\n    op_def=op_def)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2260, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/wayne/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1230, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "#sequence_autoencoder.fit(X_train, X_train, nb_epoch=100,\n",
    "#                         batch_size=batch_size, \n",
    "#                         shuffle=True, \n",
    "#                         validation_split=0.2,\n",
    "#                         callbacks=[early_stopping])\n",
    "sequence_autoencoder.fit([encoder_input, decoder_prev_input, decoder_next_input], \n",
    "                          [decoder_prev_target, decoder_next_target], nb_epoch=10,\n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=True, \n",
    "                         validation_split=0.2,\n",
    "                         callbacks=[early_stopping],\n",
    "                         verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1280256 /128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "98688/2580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2621440/2580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2688/128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.15625"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2580/128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129.0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2580/20.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2688/128.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "291680"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14584*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
